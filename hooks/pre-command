#!/bin/bash
set -euo pipefail
DIR="$(cd "$( dirname "${BASH_SOURCE[0]}" )" && pwd)"

# shellcheck source=lib/shared.bash
. "$DIR/../lib/shared.bash"
cache_key=$(get_cache_key)

# Set an env var to include the cache key
# This means we can skip re-uploading the same cache in the post_command
function mark_restored() {
  echo "Successfully restored $1"
  export BUILDKITE_PLUGIN_CACHE_RESTORED=${BUILDKITE_PLUGIN_CACHE_RESTORED:-}:$1:
}

echo "Restoring cache $cache_key"

bucket="${BUILDKITE_PLUGIN_CACHE_S3_BUCKET_NAME}/${BUILDKITE_ORGANIZATION_SLUG}/${BUILDKITE_PIPELINE_SLUG}/$cache_key"
tmpdir=$(mktemp -d)
# Set env var if we loaded the cache so we can skip reuploading it
aws s3 cp "s3://${bucket}/cache.tar.gz" "$tmpdir/" && mark_restored "$cache_key" || echo "Cache not found"
tar -xzf "$tmpdir/cache.tar.gz"
rm -rf "$tmpdir"
